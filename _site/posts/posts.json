[
  {
    "path": "posts/2022-07-06-classification-based-prediction-of-carbon-emission/",
    "title": "Classification based Prediction of Carbon Emission",
    "description": "Dissertation done during M.Sc program. You can check the report from the following [report link](https://1drv.ms/b/s!ApFYtM4ZFefbgxpGtypiPWaMjT_1)",
    "author": [
      {
        "name": "Md Jaffar Mollah",
        "url": {}
      }
    ],
    "date": "2022-07-06",
    "categories": [
      "clustering",
      "classification",
      "GLM",
      "Robust GLM"
    ],
    "contents": "\n\nContents\nIntroduction\nDealing with data\nImporting and\ndescription\nDescriptive Statistics\nCorrelation matrix\n\nVariable Selection\nBased on descriptive\nBased on correlation\nmatrix\nBased on stepwise\nregression\n\nCreating functions\nDay Forward Technique\nPredict Second Half\nTechnique\nModel Building\nModel Graph Display\nPrediction Error\n\nFeature Scaling\nTrain and Test set\nClustering\nData Manipulation\nDistance Matrix\nCluster number choice\nPAM Algorithm\nPlotting clusters\nMap Visualization\nDescriptive\nStatistics of clustered countries\nMerging levels of\ncertain fields\n\nData Modeling\nDistibution of\ndependent variable\nPerformance Evaluation\nModeling\nModel Adequacy Checking\n\nClassification\nDecision Trees\nSupport Vector Machine\nCategorizing carbon\nemission\n\nPrediction with test\ndata\nLooking at the\ntransition\nConclusion\n\nIntroduction\nThe project is based on devising an approach to model carbon emission\nbased on longitudinal data for different countries (100 in number). Due\nto limitation in the available data, the approach is thought to\ncarefully look into statistical properties while preparing the models.\nHere the data (secondary data) available is taken from different sources\nand consolidated into a single structured data that can be used for\nmodeling.\nNote - Also making small changes to the code for better presentation\nin the blog. But the approach to the problem is similar to the report\nprovided.\nDealing with data\nThe data for different countries have been drawn from different\nsources. Please refer to Section 6.2 in the report for\nknowing the sources and the description of the fields taken.\nImporting and description\nThe structured data is created by combining data from different\nsources into one single dataset. The dataset consists of 100 countries\nas subjects with initially 14 variables across 10 years time period\n(2007-2016).\n\n\n#importing file\ncarbon <- read.csv('final_data_climate_change.csv', header = T)\ncarbon.copy <- carbon\n\n#variable names of the dataframe\nnames(carbon)\n\n\n [1] \"country_code\"  \"countries\"     \"year\"          \"pop_total\"    \n [5] \"co2emission\"   \"gnipercapita\"  \"fuel_export\"   \"fuel_import\"  \n [9] \"gdp\"           \"forest_area\"   \"agri_area\"     \"land_area\"    \n[13] \"temp_change\"   \"ind_hdi\"       \"ind_inflation\" \"ind_elec\"     \n\nattach(carbon)\n\n\n\nDescriptive Statistics\nAs initial steps, we need to have a careful look at the various\ninformation about all the variables. The descriptive information can be\ninterpreted based on subject knowledge and how different fields are\ngoing to affect the model.\n\n\nlibrary(psych)\n\noptions(scipen = 99999)\n\ndescribe(carbon[, 4:13], fast = TRUE)\n\n\n             vars    n             mean               sd\npop_total       1 1000      56411714.72     185569765.44\nco2emission     2 1000           291.94          1069.18\ngnipercapita    3 1000         20319.67         17117.51\nfuel_export     4 1000 1699617118421.82 4371982939893.39\nfuel_import     5 1000 2284152539170.12 5561244475837.46\ngdp             6 1000  642442089374.03 1932922384003.83\nforest_area     7 1000        329230.34       1056658.29\nagri_area       8 1000        380194.19        870846.62\nland_area       9 1000        993216.37       2460856.45\ntemp_change    10 1000             1.04             0.55\n                       min               max             range\npop_total        167639.00     1378665000.00     1378497361.00\nco2emission           0.38           9820.36           9819.98\ngnipercapita        772.00          91519.00          90747.00\nfuel_export        1360.41 37500000000000.00 37499999998639.59\nfuel_import   294481364.90 50300000000000.00 50299705518635.10\ngdp          1278745519.00 18700000000000.00 18698721254481.00\nforest_area           3.50        8151356.25        8151352.75\nagri_area            82.00        5278330.00        5278248.00\nland_area           320.00       16377740.00       16377420.00\ntemp_change          -0.32              2.94              3.26\n                          se\npop_total         5868231.24\nco2emission            33.81\ngnipercapita          541.30\nfuel_export  138254239814.62\nfuel_import  175861991686.76\ngdp           61124372737.75\nforest_area         33414.47\nagri_area           27538.59\nland_area           77819.11\ntemp_change             0.02\n\n#checking the categorical variables\ntable(ind_hdi)\n\n\nind_hdi\n     high       low    medium Very high \n      284       147       151       418 \n\ntable(ind_inflation)\n\n\nind_inflation\n    creeping/low        deflation        galloping          running \n             497              103               40               87 \nwalking/moderate \n             273 \n\ntable(ind_elec)\n\n\nind_elec\n     high       low  moderate very high  very low \n       32        44        51       818        55 \n\ntable(ind_elec,year)\n\n\n           year\nind_elec     1  2  3  4  5  6  7  8  9 10\n  high       4  3  3  3  3  3  2  3  3  5\n  low        3  4  3  3  5  4  4  6  6  6\n  moderate   5  5  6  6  5  6  5  4  5  4\n  very high 81 81 81 81 81 81 83 83 83 83\n  very low   7  7  7  7  6  6  6  4  3  2\n\nCorrelation matrix\nLooking at the distribution of dependent variable and correlation\nmatrix between different variables\n\n\n# finding correlation between numerical variables\nlibrary(psych)\npairs.panels(\n  carbon[, 4:13],\n  method = \"pearson\",\n  hist.col = \"#00AFBB\",\n  density = TRUE,\n  ellipses = F,\n  main = \"Correlation and scatter plot of the data\"\n)\n\n\n\n\nVariable Selection\nBased on descriptive\nind_elec: One level of this variable is having high frequency and\nhence it can be considered insignificant.\nfuel_export and fuel_import : Since the values of these are already\nincluded in the gdp variable this can result in double counting hence it\ncan be dropped\nland_area: Since this area includes agri_area and forest_area so\nthere will be double counting and hence we can drop this variable\nBased on correlation matrix\ntemp_change: Since this variable is having almost no correlation\nwith response variable and also based on geographical understanding\ntemp_change does not influence co2 emission but its the other way\nround.\n\n\n#dropping the above variables\ncarbon <- carbon[, c(-7, -8, -12, -13, -16)]\n\n#Standardizing the numerical variables to remove the unit problem and high value variables\ncarbon[, 4:9] <- scale(carbon[, 4:9], center = T, scale = T) + 3\n\n\n\nNote: We are trying to make a basic model after dropping the above\nvariables and again conducting the stepwise regression for statistical\nsignificance\n\n\n#creating basic glm model\nobj <-\n  glm(\n    formula = co2emission ~ .,\n    data = carbon[, 3:11],\n    family = Gamma(link = inverse)\n  )\nsummary(obj)\nhist(obj$residuals, xlab = \"Residuals\",\n     main = \"Distribution of Residuals\")\n\n\n\n\nBased on stepwise regression\n\n\n#Going for stepwise regression and checking if significance of variables\nstep(obj, direction = \"both\")\n\n\nStart:  AIC=-1262.2\nco2emission ~ year + pop_total + gnipercapita + gdp + forest_area + \n    agri_area + ind_hdi + ind_inflation\n\n                Df Deviance      AIC\n- gnipercapita   1   1.8804 -1264.13\n<none>               1.8803 -1262.20\n- ind_inflation  4   1.9039 -1257.98\n- ind_hdi        3   1.9496 -1232.35\n- year           1   1.9811 -1212.07\n- agri_area      1   2.1032 -1148.94\n- forest_area    1   2.3513 -1020.66\n- gdp            1   5.4292   570.64\n- pop_total      1   5.9903   860.76\n\nStep:  AIC=-1264.13\nco2emission ~ year + pop_total + gdp + forest_area + agri_area + \n    ind_hdi + ind_inflation\n\n                Df Deviance      AIC\n<none>               1.8804 -1264.13\n+ gnipercapita   1   1.8803 -1262.20\n- ind_inflation  4   1.9048 -1259.50\n- year           1   1.9827 -1213.21\n- ind_hdi        3   2.0372 -1188.99\n- agri_area      1   2.1037 -1150.61\n- forest_area    1   2.3517 -1022.25\n- gdp            1   5.6501   684.60\n- pop_total      1   6.1682   952.68\n\nCall:  glm(formula = co2emission ~ year + pop_total + gdp + forest_area + \n    agri_area + ind_hdi + ind_inflation, family = Gamma(link = inverse), \n    data = carbon[, 3:11])\n\nCoefficients:\n                  (Intercept)                           year  \n                    0.4958884                      0.0011904  \n                    pop_total                            gdp  \n                   -0.0190026                     -0.0172498  \n                  forest_area                      agri_area  \n                   -0.0075838                     -0.0074414  \n                   ind_hdilow                  ind_hdimedium  \n                    0.0061039                     -0.0011646  \n             ind_hdiVery high         ind_inflationdeflation  \n                   -0.0073186                     -0.0050900  \n       ind_inflationgalloping           ind_inflationrunning  \n                    0.0006821                     -0.0005409  \nind_inflationwalking/moderate  \n                    0.0009651  \n\nDegrees of Freedom: 999 Total (i.e. Null);  987 Residual\nNull Deviance:      51.28 \nResidual Deviance: 1.88     AIC: -1264\n\ngnipercapita: By looking at the stepwise regression we can say that\nthis variable is insignificant and hence can be dropped.\n\n\n#From stepwise we see that gnipercapita can also be dropped\n#Finally we get the variables for modeling as\ncarbon <- carbon[, -6]\nvar_name <- names(carbon)\n\n\n\n\n\n\nCreating functions\nDay Forward Technique\n\n#Performance Evaluation of training set using day forward technique\n#GLM Model\nday_forward.glm <- function(x) {\n  ...Refer to report (Chapter 7)\n}\n\n# Robust Regression\nday_forward.glmrob <- function (x) {\n  ...Refer to report (Chapter 7)\n}\n\nPredict Second Half\nTechnique\n\n#Performance Evaluation of training set using Predict second half technique\n#GLM Model\npredict_second_half.glm <- function(x) {\n  ...Refer to report (Chapter 7)\n}\n\n# Robust Regression\npredict_second_half.glmrob <- function (x) {\n  ...Refer to report (Chapter 7)\n}\n\nModel Building\n\n#Function for model building\n#GLM Model\nmodel.glm <- function (x) {\n  ...Refer to report (Chapter 7)\n}\n\n#Robust GLM Model\nmodel.glmrob <- function (x) {\n  ...Refer to report (Chapter 7)\n}\n\nModel Graph Display\n\n#Function for graphical display\n#GLM Model\ndraw.glm <- function(object,st) {\n  # Model Adequacy Checking\n  # Residual Plots\n  # QQ plots\n  ...Refer to report (Chapter 7)\n}    \n\n#Robust GLM Model\ndraw.glmrob <- function (object,st) {\n  # Model Adequacy Checking\n  # Residual Plots\n  # QQ plots\n  ...Refer to report (Chapter 7)\n}\n\nPrediction Error\n\n #Prediction error function\n #GLM Model\n predicterror.glm <- function(object,z) {\n   ...Refer to report (Chapter 7)\n }\n \n #Robust GLM Model\n predicterror.glmrob <- function(object,z) {\n   ...Refer to report (Chapter 7)\n}\n\n\n\n\nFeature Scaling\n\n\n### Feature scaling\ncarbon[, 4:8] <- scale(carbon[, 4:8]) + 3\n\n\n\nTrain and Test set\nTaking the first 8 years as training set and last 2 years as test set\nfor validation of model on the overall dataset.\n\n\n##Splitting the data into train and test\ntraining_set = carbon[carbon$year >= 1 & carbon$year <= 8, ]\ntest_set = carbon[carbon$year == 9 | carbon$year == 10, ]\n\n\n\nClustering\nWe already know that for every country the carbon emission will not\nbe same. For big or developed and developing countries it will be high\nand for smaller countries it will be low. So a single model will not be\nefficient in tackling this problem. This can be solved by grouping\ncountries based on different features and then building models based on\nthe grouping to which it belongs.\nData Manipulation\n\n\ncarbon<-carbon.copy\n\n#Converting categorical to ordinal data\nlibrary(plyr)\ncarbon$ind_hdi <-\n  mapvalues(\n    carbon$ind_hdi,\n    from = c(\"low\", \"medium\", \"high\", \"Very high\"),\n    to = c(1, 2, 3, 4)\n  )\ncarbon$ind_inflation <- mapvalues(\n  carbon$ind_inflation,\n  from = c(\n    \"deflation\",\n    \"creeping/low\",\n    \"walking/moderate\",\n    \"running\",\n    \"galloping\"\n  ),\n  to = c(1, 2, 3, 4, 5)\n)\n\ncarbon$ind_hdi = as.factor(carbon$ind_hdi)\ncarbon$ind_inflation = as.factor(carbon$ind_inflation)\n\n#Bringing the variables to same level through transformation\ncarbon[, 4:8] <- log(carbon[, 4:8])\n\n#Normalizing the variables both continuous and ordinal\nlibrary(BBmisc)\ncarbon[, 4:10] <- normalize(carbon[, 4:10], method = \"range\", range = c(0, 1))\n\n\n\nDistance Matrix\n\n\ndd <- matrix(0, nrow = 100, ncol = 100)\ncc <- matrix(0, nrow = 100, ncol = 100)\nfor (i in 1:10)\n{\n  carb_clus <- carbon[carbon$year == i, c(-1, -3)]\n  cc <- as.matrix(dist(carb_clus[, -1], method = 'euclidean'))\n  cc <- cc ^ 2\n  dd = dd + cc\n}\ndd = sqrt(dd)\n\n\n\nCluster number choice\n\n\n#Elbow method\nlibrary(cluster)\nsil_width <- c(NA)\nfor (i in 2:10)\n{\n  pam_fit <- pam(dd, diss = TRUE, k = i)\n  sil_width[i] <- pam_fit$silinfo$avg.width\n}\n\n# Plot sihouette width (higher is better)\nplot(1:10, sil_width,\n     xlab = \"Number of clusters\",\n     ylab = \"Silhouette Width\")\nlines(1:10, sil_width)\n\n\n\n\nPAM Algorithm\n\n\n#By looking at plot, optimal no of cluster is 3\npam_fit <- pam(dd, diss = TRUE, k = 3)\npam_cluster = pam_fit$clustering\npam_cluster\n\n#Preparing cluster list\ncluster_list <- data.frame(carbon[carbon$year == 1, 2], pam_cluster)\nnames(cluster_list) <- c(\"countries\", \"cluster_no\")\n\n\n\nPlotting clusters\n\n\n#Plotting cluster numbers in a graph\nlibrary(Rtsne)\ntsne_obj <- Rtsne(dd, is_distance = TRUE)\nlibrary(magrittr) # needs to be run every time you start R and want to use %>%\nlibrary(dplyr)\ntsne_data <- tsne_obj$Y %>%\n  data.frame() %>%\n  setNames(c(\"X\", \"Y\")) %>%\n  mutate(cluster = factor(pam_cluster),\n         name = cluster_list$countries)\n\nlibrary(ggplot2)\nggplot(aes(x = X, y = Y), data = tsne_data) +\n  geom_point(aes(color = cluster), size = 3)\n\nlibrary(dplyr)\ncarbon_clus.submodel <-\n  left_join(carbon.copy, cluster_list, by = \"countries\")\ncarbon_clus.classify <- left_join(carbon, cluster_list, by = \"countries\")\n\n\n\n\nMap Visualization\n\n\nlibrary(googleVis)\nWorldMap = cluster_list\nG5 <- gvisGeoChart(\n  WorldMap,\n  \"countries\",\n  \"cluster_no\",\n  options = list(\n    displayMode = 'auto',\n    dataMode = \"regions\",\n    colorAxis = \"{colors:['blue', 'red','green']}\",\n    backgroundColor = \"lightblue\",\n    width = 800,\n    height = 400,\n    legend = \"{colors:['blue','red','green']}\"\n  )\n)\n\nplot(G5)\n#Only countries not plotted-Malta,Bahrain,Barbados,St. Lucia due to small area size\n\n\n\n\nDescriptive\nStatistics of clustered countries\n\n\n\n\nMerging levels of certain\nfields\nIn 1st cluster - ind_hdi ==> low level + medium level -\nind_inflation ==> galloping + running\nIn 2nd Cluster - ind_hdi ==> low + medium\nIn 3rd cluster - ind_hdi ==> Very high + high + medium -\nind_inflation ==> galloping + running\n\n\n\nData Modeling\nDistibution of dependent\nvariable\n\n\n# taking the variable co2emission\nsummary(co2emission)\nlibrary (ggplot2)\nlibrary(ggplot2)\nggplot(carbon, aes(x = co2emission)) +\n  geom_histogram(aes(y = ..count..),\n                 color = \"black\",\n                 fill = \"grey\",\n                 bins = 15) +\n  ylab(\"Frequency of the variable\") +\n  xlab(\"Carbon Dioxide Emission\") +\n  ggtitle(\"Histogram of carbon dioxide emission of complete data\") +\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_rect(fill = \"transparent\", colour = NA),\n    plot.background = element_rect(fill = \"transparent\", colour = NA),\n    plot.title = element_text(hjust = 0.5)\n  )\n\n\n\n\nPerformance Evaluation\nGLM\nRobust GLM\n\n\n#Performance Evaluation of training set using day forward technique\nday_forward.glm(training_set)\nday_forward.glmrob(training_set)\n\n#Performance Evaluation of training set using predict second half technique\npredict_second_half.glm(training_set)\npredict_second_half.glmrob(training_set)\n\n\n\n\nModeling\nGLM\nRobust GLM\n\n\nobj1 = model.glm(training_set)\nsummary(obj1)\n\nobj2 = model.glmrob(training_set)\nsummary(obj2)\n\n\n\nModel Adequacy Checking\nGLM\nRobust GLM\n\n\ndraw.glm(obj1, \"GLM Complete Data\")\npredicterror.glm(obj1, test_set)\n\n\n\n\n\n\ndraw.glmrob(obj2, \"Robust GLM Complete Data\")\npredicterror.glmrob(obj2, test_set)\n\n\n\n\nClassification\n\n\ndata <- carbon_clus.classify\ndata$cluster_no <- as.factor(data$cluster_no)\n\n#Splitting the data into training and test based on earlier criteria\ntraining_set = data[data$year >= 1 & data$year <= 8, -c(1, 2, 3)]\ntest_set = data[data$year == 9 | data$year == 10, -c(1, 2, 3)]\n\n\n\nDecision Trees\n\n\n######################## DECISION TREE #################################\n#Decision trees dont need any preprocessing\n#Works fine on actual values as well but due to large number we only do log\n#transformation on the continuous variables\n\nlibrary(rpart)\ndata <- carbon_clus.submodel\ndata[, 4:8] <- scale(data[, 4:8]) + 3\ndata$cluster_no <- as.factor(data$cluster_no)\n#Splitting the data into training and test based on earlier criteria\ntraining_set = data[data$year >= 1 & data$year <= 8, -c(1, 2, 3)]\ntest_set = data[data$year == 9 | data$year == 10, -c(1, 2, 3)]\nclassobj2 <- rpart(formula = cluster_no ~ .,\n                   data = training_set,\n                   control = rpart.control(minsplit = 1))\npred = predict(classobj2, test_set[, -8], type = 'class')\nt2 <- as.matrix(table(pred, test_set[, 8]))\nrownames(t2) = c(\"\", \"Pedicted\", \"\")\ncolnames(t2) = c(\"\", \"Actual\", \"\")\ncat(\"Accuracy Score: \", sum(diag(t2)) / nrow(test_set) * 100, \"%\\n\")\nlibrary(rpart.plot)\nrpart.plot(classobj2,\n           box.palette = \"RdBu\",\n           shadow.col = \"gray\",\n           nn = TRUE)\n\n\n\n\nSupport Vector Machine\n\n\n#################### SVM ######################################\nlibrary(e1071)\nclassobj1 <-\n  svm(formula = cluster_no ~ .,\n      data = training_set,\n      kernel = 'radial')\nsummary(classobj1)\npred = predict(classobj1, test_set[, -8])\nt1 <- as.matrix(table(pred, test_set[, 8]))\nrownames(t1) = c(\"\", \"Pedicted\", \"\")\ncolnames(t1) = c(\"\", \"Actual\", \"\")\ncat(\"Accuracy Score: \", sum(diag(t1)) / nrow(test_set) * 100, \"%\\n\")\n\n\n\nCategorizing carbon emission\n\n\n#Categorizing carbon emission\ncarbon_category <- function(x)\n{\n  if (x >= 600)\n  {\n    status = 'Extremely High'\n  } else{\n    if (x >= 200 & x < 600)\n    {\n      status = 'Very High'\n    } else\n    {\n      if (x >= 100 & x < 200)\n      {\n        status = 'High'\n      } else{\n        if (x >= 50 & x < 100)\n        {\n          status = 'Moderate'\n        } else{\n          if (x >= 20 & x < 50)\n          {\n            status = 'Low'\n          } else{\n            status = 'Safe'\n          }\n        }\n      }\n    }\n  }\n  return(status)\n}\n\n\n\nPrediction with test data\n\n\n###################### Prediction Result for our study\n# Ready to classify using SVM\nstudydata1 = carbon_clus.classify[carbon_clus.classify$year == 9, ]\n\n#Predicting the class\npredclass = predict(classobj1, studydata1)\nc1 = which(predclass == '1')\nc2 = which(predclass == '2')\nc3 = which(predclass == '3')\n\n#Predicting carbon emission after preprocessing\nstudydata2 = carbon[carbon$year == 9 | carbon$year == 10, ]\n\n#Use submodel1 for cluster1 , complete data model for cluster2 , submodel3 for cluster3\ndata1 = mergelevel(studydata2[c1, ] , '1')\ndata2 = studydata2[c2 ,]\ndata3 = mergelevel(studydata2[c3, ] , '3')\npredval1 = predict(subobj1 , data1 , type = \"response\")\npredval2 = predict(obj , data2 , type = \"response\")\npredval3 = predict(subobj3 , data3 , type = \"response\") \npredcarbon = data.frame(rbind(data1[, 2:3], \n                              data2[, 2:3], \n                              data3[, 2:3]),\n                        c(predval1 , predval2 , predval3))\nnames(predcarbon) = c(\"countries\", \"year\", \"pred emission\")\n\n\n\n\nLooking at the transition\n\n\n########### Study carbon status history \n#Checking status of predicted value\npredemission_status = vector()\nfor (i in 1:nrow(predcarbon))\n  predemission_status[i] = carbon_category(predcarbon[i , 3])\npredcarbon = cbind(predcarbon, predemission_status)\n\nlibrary(dplyr)\ncarbon_map = cbind(paste0(carbon_map[, 1] , carbon_map[, 2]) , carbon_map)\nnames(carbon_map) <-\n  c(\"countries year\",\n    \"countries\" ,\n    \"year\" ,\n    \"co2emission\" ,\n    \"emission status\")\ncountries_year = paste0(predcarbon[, 1] , predcarbon[, 2])\npredcarbon = cbind (countries_year , predcarbon)\npredcarbon = predcarbon[, -c(2 , 3)]\nhiststudy = left_join(carbon_map, predcarbon , by = \"countries year\")[, -1]\n\nt0 = table(histstudy [histstudy$year == 9 | histstudy$year == 10, 4],\n           histstudy[histstudy$year == 9 | histstudy$year == 10, 6])\naccuracy = (sum (diag(t0)) / 200) * 100\naccuracy\nt1 = table(histstudy[histstudy$year == 1, 4],\n           histstudy [histstudy$year == 8, 4]) \nt2 = table(histstudy[histstudy$year == 1, 4], \n           histstudy [histstudy$year == 9, 6])\n\ncat(\"Row vs Column:Year 1 vs Year 8\\n\")\nt1\ncat(\"Row vs Column:Year 1 vs Year 9\\n\")\nt2\ncat(\"Year 1 vs Year 8: Transition of change(Count)\",\n    100 - sum(diag(t1)),\"\\n\") \ncat(\"Year 1 vs Year 9: Transition of change(Count)\",\n    100 - sum(diag(t2)),\"\\n\")\n\n\n\n\nConclusion\nIn our study, we have dealt with an approach to predict carbon\ndioxide emission based on the classification of the countries. The study\ncan help to understand the dynamics of climate change in a more better\nway than just going for a descriptive analysis. In our study, we first\nclassify the data based on the features and based on the label predicted\nwe choose the model to predict the carbon dioxide emission. On\nprediction of the carbon dioxide emission, we know the status of carbon\nemission through the categories created and we study the historical\nemissions of the countries and see the jump in the status of the\ncountries.\nIn our analysis, we see that R squared measure cannot be taken as a\ncriteria for judgment of models since as variation in the response\nvariable reduces drastically, the R squared value deteriorates although\nthe prediction power measured through MSE is good.By looking at the\nvalidation table, we see that sub-model 1 and sub-model 3 are the best\nmodels with not much variation between Robust GLM and GLM models.\nSub-model 2 deteriorates year wise and hence it is not appropriate for\nprediction. Instead we can use complete model in place of sub-model 2.\nIt has been observed that most of the time GLM model proves to be better\nthat robust GLM model but for countries with high values or extreme\nvalues, Robust GLM is the best choice. It was noticed that due to\nextreme values there is deviation in the assumptions in the tail ends as\nvisible in model adequacy checking.\nIn the classification problem, we see that SVM performs better than\ndecision trees and hence SVM was used in our predictions irrespective of\nthe year since we have made classifier considering data to be\nindependent of time. But based on subject knowledge, decision trees are\nsupposed to be better classifier for longitudinal data. So, this thing\ncan be kept in mind while performing classification. After\nclassification we perform prediction based on the models selected for\nthe groups. Predicted values are categorized to see the transition that\nhas occurred over the years by the 100 countries.\nAfter the prediction and categorization we see that there is an\nincrease in the number of countries which has shown transition between\nyear 1 and year 9 from year 1 and year 8. This analysis can be more\nrefined by analyzing individual countries but currently this is not part\nof our study. Hence, we conclude that even with limitation of data(due\nto smoothed data by secondary sources) we can say that this approach is\nvery helpful in understanding the dynamics of carbon emission by\ncountries over the years.\nFuture studies can involve multivariate longitudinal analysis,\nmultivariate time series forecasting and machine learning as techniques\nto get better results. A minor study was made with some machine learning\nmodel(not included in the study) and it was seen that it performed\nbetter than statistical models. Also considering the complex nature of\nthe topic and various complexities in the analysis and limitation of\ndata, machine learning proves to be an apt technique in this field. This\nstudy was done to explain the approach in predicting carbon emission and\nmaking a useful analysis that can help in building a sustainable world\nin future. It is just a small contribution in our fight to reduce carbon\nemission and save our planet.\n\n\n\n",
    "preview": "posts/2022-07-06-classification-based-prediction-of-carbon-emission/clustermap.jpg",
    "last_modified": "2022-07-07T04:41:32+05:30",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to My Blog",
    "description": "Welcome to our new blog, My Blog. We hope you enjoy \nreading what we have to say!",
    "author": [
      {
        "name": "Nora Jones",
        "url": "https://example.com/norajones"
      }
    ],
    "date": "2022-07-06",
    "categories": [],
    "contents": "\n\n\n\n",
    "preview": {},
    "last_modified": "2022-07-06T13:28:08+05:30",
    "input_file": {}
  }
]
